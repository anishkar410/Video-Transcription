{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04x4n8DmFSYq",
        "outputId": "f4da1cd8-a202-46b8-809a-8e12d17371b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# 1) Colab install: prefers faster-whisper on Py<=3.11, falls back to openai-whisper on Py>=3.12 ---\n",
        "import sys, subprocess, textwrap\n",
        "py_minor = sys.version_info.minor\n",
        "\n",
        "!pip -q install --upgrade pip\n",
        "\n",
        "COMMON = [\n",
        "    \"yt-dlp==2025.1.26\",\n",
        "    \"pydub==0.25.1\",\n",
        "    \"librosa==0.10.2.post1\",\n",
        "    \"soundfile==0.12.1\",\n",
        "    \"noisereduce==3.0.2\",\n",
        "    \"rich==13.7.1\",\n",
        "]\n",
        "\n",
        "if py_minor <= 11:\n",
        "    # Preferred path (fast + accurate)\n",
        "    !pip -q install \"ctranslate2==4.4.0\" \"faster-whisper==1.0.1\" { \" \".join(COMMON) }\n",
        "else:\n",
        "    # Python 3.12+ fallback (very accurate, slower)\n",
        "    !pip -q install \"openai-whisper==20240930\" { \" \".join(COMMON) }\n",
        "\n",
        "!apt -y -qq install ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToFG2slZNfJ9",
        "outputId": "cfcc52e3-0122-44db-d595-fc6500008279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip -q install --upgrade pip\n",
        "!pip -q install faster-whisper==1.0.3\n",
        "!apt -y -qq install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backend auto-detect\n",
        "BACKEND = None\n",
        "try:\n",
        "    from faster_whisper import WhisperModel\n",
        "    BACKEND = \"faster\"\n",
        "except Exception:\n",
        "    import whisper as whisper_og\n",
        "    BACKEND = \"openai\"\n",
        "\n",
        "import torch\n",
        "CUDA_OK = torch.cuda.is_available()\n",
        "DEVICE = \"cuda\" if CUDA_OK else \"cpu\"\n",
        "\n",
        "def pick_compute_type():\n",
        "    if DEVICE == \"cuda\":\n",
        "        return \"int8_float16\"   # fast & accurate on GPU (faster-whisper only)\n",
        "    return \"int8\"\n"
      ],
      "metadata": {
        "id": "81yPnvPdFkc5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) IMPORTS & UTILITIES\n",
        "import os, re, io, json, math, tempfile, subprocess, shutil, sys, time\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "from pydub import AudioSegment, effects\n",
        "import librosa\n",
        "import noisereduce as nr\n",
        "from rich import print as rprint\n",
        "from google.colab import files\n",
        "\n",
        "# faster-whisper\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "# Hardware selection\n",
        "import torch\n",
        "CUDA_OK = torch.cuda.is_available()\n",
        "DEVICE = \"cuda\" if CUDA_OK else \"cpu\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVfLbxImNzO1",
        "outputId": "76704b8f-4a7b-4114-9711-cf0b67ed811e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:300: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m = re.match('([su]([0-9]{1,2})p?) \\(([0-9]{1,2}) bit\\)$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:301: SyntaxWarning: invalid escape sequence '\\('\n",
            "  m2 = re.match('([su]([0-9]{1,2})p?)( \\(default\\))?$', token)\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:310: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(flt)p?( \\(default\\))?$', token):\n",
            "/usr/local/lib/python3.12/dist-packages/pydub/utils.py:314: SyntaxWarning: invalid escape sequence '\\('\n",
            "  elif re.match('(dbl)p?( \\(default\\))?$', token):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spacing for Hindi + English text\n",
        "def smart_space_fix(text):\n",
        "\n",
        "    if not text:\n",
        "        return text\n",
        "\n",
        "    #  Ensuring a space after punctuation if next char isn't space\n",
        "    text = re.sub(r'([,;:!?])(?!\\s)', r'\\1 ', text)\n",
        "    # Support Hindi danda/ dandi\n",
        "    text = re.sub(r'(।)(?!\\s)', r'\\1 ', text)\n",
        "\n",
        "    #  Removing extra spaces BEFORE punctuation\n",
        "    text = re.sub(r'\\s+([,;:!?।])', r'\\1', text)\n",
        "\n",
        "    # Adding a space at script boundaries (Devanagari <-> Latin/number)\n",
        "    # Devanagari range: \\u0900-\\u097F\n",
        "    text = re.sub(r'([\\u0900-\\u097F])([A-Za-z0-9])', r'\\1 \\2', text)\n",
        "    text = re.sub(r'([A-Za-z0-9])([\\u0900-\\u097F])', r'\\1 \\2', text)\n",
        "\n",
        "    # Splitting common glued Hindi function words on both sides\n",
        "    common = ['है','हैं','था','थी','थे','भी','पर','और','या','कि','जो','जब','जहाँ','क्यों','तो','ना','में','से','के']\n",
        "    for w in common:\n",
        "        # add space before the word if preceded by a Devanagari letter w/o space\n",
        "        text = re.sub(rf'([\\u0900-\\u097F])({w})', r'\\1 \\2', text)\n",
        "        # add space after the word if followed by a Devanagari letter w/o space\n",
        "        text = re.sub(rf'({w})([\\u0900-\\u097F])', r'\\1 \\2', text)\n",
        "\n",
        "    # 5) Normalize multiple spaces\n",
        "    text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "\n",
        "def collapse_word_runs(text, max_repeat=3):\n",
        "\n",
        "    if not text: return text\n",
        "    tokens = re.findall(r'\\w+|[^\\w\\s]', text, flags=re.UNICODE)\n",
        "    out = []\n",
        "    run_word = None\n",
        "    run_len = 0\n",
        "    for tok in tokens:\n",
        "        # treat words separately from punctuation\n",
        "        if re.match(r'\\w+', tok, flags=re.UNICODE):\n",
        "            if tok == run_word:\n",
        "                run_len += 1\n",
        "                if run_len <= max_repeat:\n",
        "                    out.append(tok)\n",
        "            else:\n",
        "                run_word = tok\n",
        "                run_len = 1\n",
        "                out.append(tok)\n",
        "        else:\n",
        "            # reset run on punctuation\n",
        "            run_word = None\n",
        "            run_len = 0\n",
        "            out.append(tok)\n",
        "    # Re-join with spaces where appropriate\n",
        "    txt = \"\"\n",
        "    for i, t in enumerate(out):\n",
        "        if i and re.match(r'\\w+', t, flags=re.UNICODE) and re.match(r'\\w+', out[i-1], flags=re.UNICODE):\n",
        "            txt += \" \"\n",
        "        elif i and t.isalnum() and out[i-1].isalnum():\n",
        "            txt += \" \"\n",
        "        txt += t\n",
        "    # squeeze spaces before punctuation\n",
        "    txt = re.sub(r'\\s+([,.;:!?])', r'\\1', txt)\n",
        "    return txt.strip()\n",
        "\n",
        "def trim_low_info_tail(text, min_unique_ratio=0.25, tail_window=60):\n",
        "\n",
        "    if not text or len(text) < tail_window:\n",
        "        return text\n",
        "    head, tail = text[:-tail_window], text[-tail_window:]\n",
        "    words = re.findall(r'\\w+', tail, flags=re.UNICODE)\n",
        "    if not words:\n",
        "        return text\n",
        "    uniq = set(words)\n",
        "    ratio = len(uniq) / max(1, len(words))\n",
        "    if ratio < min_unique_ratio:\n",
        "        return head.rstrip()\n",
        "    return text\n",
        "\n",
        "def remove_repetitions(text, sim_threshold=0.72):\n",
        "    if not text: return text\n",
        "    # sentence-level dedupe (your original idea)\n",
        "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "    out = []\n",
        "    prev = \"\"\n",
        "    for s in sents:\n",
        "        s_clean = s.strip()\n",
        "        if not s_clean:\n",
        "            continue\n",
        "        if s_clean.lower() != prev.lower() and jaccard_sim(s_clean, prev) < sim_threshold:\n",
        "            out.append(s_clean)\n",
        "            prev = s_clean\n",
        "    cleaned = \" \".join(out)\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "    # NEW: word-run collapse + tail trim\n",
        "    cleaned = collapse_word_runs(cleaned, max_repeat=3)\n",
        "    cleaned = trim_low_info_tail(cleaned, min_unique_ratio=0.25, tail_window=80)\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def pick_compute_type():\n",
        "    \"\"\"\n",
        "    Heuristic for stable GPU/CPU precision that avoids OOM but keeps accuracy high.\n",
        "    \"\"\"\n",
        "    if DEVICE == \"cuda\":\n",
        "        # Use mixed int8/float16 on consumer GPUs for Large-v3\n",
        "        return \"int8_float16\"\n",
        "    # CPU path\n",
        "    return \"int8\"  # CTranslate2 quantization for speed on CPU\n",
        "\n",
        "def human_bytes(n):\n",
        "    units = [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]\n",
        "    i = 0\n",
        "    while n >= 1024 and i < len(units)-1:\n",
        "        n /= 1024.0; i += 1\n",
        "    return f\"{n:.1f} {units[i]}\"\n",
        "\n",
        "\n",
        "# 3) MEDIA HELPERS (FFmpeg-based)\n",
        "\n",
        "def run_ffmpeg(cmd_args, quiet=True):\n",
        "    base = [\"ffmpeg\", \"-y\"]\n",
        "    if quiet:\n",
        "        base += [\"-hide_banner\", \"-loglevel\", \"error\"]\n",
        "    proc = subprocess.run(base + cmd_args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    if proc.returncode != 0:\n",
        "        raise RuntimeError(proc.stderr.decode(\"utf-8\", errors=\"ignore\"))\n",
        "    return True\n",
        "\n",
        "def extract_wav_16k_mono(input_path, out_path):\n",
        "    # 16kHz mono, 16-bit PCM (s16le)\n",
        "    run_ffmpeg([\n",
        "        \"-i\", input_path,\n",
        "        \"-vn\",\n",
        "        \"-ac\", \"1\",\n",
        "        \"-ar\", \"16000\",\n",
        "        \"-c:a\", \"pcm_s16le\",\n",
        "        out_path\n",
        "    ])\n",
        "\n",
        "def normalize_lufs(audio_wav_path, target_lufs=-23.0):\n",
        "\n",
        "    # Lightweight loudness normalization using pydub effects.normalize (peak) plus gain tweak.\n",
        "    # For full EBU R128 you'd use ffmpeg loudnorm, but this keeps deps simple & fast.\n",
        "\n",
        "    audio = AudioSegment.from_wav(audio_wav_path)\n",
        "    audio = audio.set_channels(1).set_frame_rate(16000)\n",
        "    # peak normalize\n",
        "    audio = effects.normalize(audio)\n",
        "\n",
        "    audio = audio.apply_gain(0.0)\n",
        "    audio.export(audio_wav_path, format=\"wav\")\n",
        "\n",
        "def reduce_noise(audio_wav_path, out_path=None, prop_decrease=0.7):\n",
        "\n",
        "    y, sr = librosa.load(audio_wav_path, sr=16000, mono=True)\n",
        "\n",
        "    # Build a small noise profile from head (fallback: simple median)\n",
        "    profile_len = min(len(y), int(0.5 * sr))\n",
        "    y_noise = y[:profile_len] if profile_len > 0 else None\n",
        "\n",
        "    try:\n",
        "        y_nr = nr.reduce_noise(\n",
        "            y=y,\n",
        "            sr=sr,\n",
        "            y_noise=y_noise,          # ok to pass None in v3.x\n",
        "            stationary=True,\n",
        "            prop_decrease=prop_decrease\n",
        "        )\n",
        "    except TypeError:\n",
        "\n",
        "        y_nr = nr.reduce_noise(\n",
        "            y=y,\n",
        "            sr=sr,\n",
        "            stationary=True,\n",
        "            prop_decrease=prop_decrease\n",
        "        )\n",
        "\n",
        "    # Normalize to prevent clipping\n",
        "    peak = np.max(np.abs(y_nr)) or 1.0\n",
        "    y_nr = y_nr / peak\n",
        "\n",
        "    if out_path is None:\n",
        "        out_path = audio_wav_path\n",
        "    sf.write(out_path, y_nr, sr)\n",
        "    return out_path\n",
        "\n",
        "\n",
        "# 4) YT DOWNLOAD\n",
        "\n",
        "def download_youtube_wav(url, out_wav=\"yt_audio_16k.wav\"):\n",
        "\n",
        "    # temp output (m4a/webm)\n",
        "    base = \"yt_tmp_audio\"\n",
        "    # extract-audio wav can be brittle; we keep original then convert ourselves.\n",
        "    ytdlp_cmd = [\n",
        "        \"yt-dlp\",\n",
        "        \"-f\", \"bestaudio/best\",\n",
        "        \"-o\", f\"{base}.%(ext)s\",\n",
        "        url\n",
        "    ]\n",
        "    proc = subprocess.run(ytdlp_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "    if proc.returncode != 0:\n",
        "        raise RuntimeError(proc.stderr.decode(\"utf-8\", errors=\"ignore\"))\n",
        "\n",
        "    # Find the downloaded file (unknown ext)\n",
        "    dl = None\n",
        "    for ext in (\".m4a\", \".webm\", \".mp3\", \".mp4\", \".opus\"):\n",
        "        cand = base + ext\n",
        "        if os.path.exists(cand):\n",
        "            dl = cand\n",
        "            break\n",
        "    if dl is None:\n",
        "\n",
        "        matches = list(Path(\".\").glob(\"yt_tmp_audio.*\"))\n",
        "        if matches:\n",
        "            dl = str(matches[0])\n",
        "    if dl is None:\n",
        "        raise FileNotFoundError(\"yt-dlp download failed to produce an audio file.\")\n",
        "\n",
        "    extract_wav_16k_mono(dl, out_wav)\n",
        "    try:\n",
        "        os.remove(dl)\n",
        "    except:\n",
        "        pass\n",
        "    return out_wav\n",
        "\n",
        "\n",
        "# 5) TEXT POST-PROCESSING\n",
        "\n",
        "def jaccard_sim(a, b):\n",
        "    if not a or not b: return 0.0\n",
        "    s1, s2 = set(a.lower().split()), set(b.lower().split())\n",
        "    if not s1 or not s2: return 0.0\n",
        "    inter = len(s1 & s2)\n",
        "    union = len(s1 | s2)\n",
        "    return inter / union if union else 0.0\n",
        "\n",
        "def remove_repetitions(text, sim_threshold=0.72):\n",
        "    if not text: return text\n",
        "    # split on sentence boundaries; keep ? ! .\n",
        "    sents = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "    out = []\n",
        "    prev = \"\"\n",
        "    for s in sents:\n",
        "        s_clean = s.strip()\n",
        "        if not s_clean: continue\n",
        "        if s_clean.lower() != prev.lower() and jaccard_sim(s_clean, prev) < sim_threshold:\n",
        "            out.append(s_clean)\n",
        "            prev = s_clean\n",
        "    # Clean joins\n",
        "    cleaned = \" \".join(out)\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
        "    return cleaned\n",
        "\n",
        "def context_aware_corrections(text):\n",
        "    if not text: return text\n",
        "\n",
        "    corrections = [\n",
        "        (r'\\bi\\b', 'I'),\n",
        "        (r'\\bu\\b', 'you'),\n",
        "        (r'\\bur\\b', 'your'),\n",
        "        (r'\\br\\b', 'are'),\n",
        "        (r'\\bpls\\b', 'please'),\n",
        "        (r'\\bthx\\b', 'thanks'),\n",
        "        (r'\\bwanna\\b', 'want to'),\n",
        "        (r'\\bgonna\\b', 'going to'),\n",
        "        (r'\\bkinda\\b', 'kind of'),\n",
        "        (r'\\bsorta\\b', 'sort of'),\n",
        "        (r'\\bgimme\\b', 'give me'),\n",
        "        (r'\\bdunno\\b', 'do not know'),\n",
        "    ]\n",
        "    for pat, repl in corrections:\n",
        "        text = re.sub(pat, repl, text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Specific pattern cleanups\n",
        "    pattern_fixes = [\n",
        "        (r'\\.\\s*\\.+', '.'),               # collapse multiple dots\n",
        "        (r'\\s+,', ','),                   # space before comma\n",
        "        (r'\\s+\\.', '.'),                  # space before period\n",
        "        (r'(\\s*\\?)\\?+', r'\\1'),           # multi question marks\n",
        "        (r'(\\s*!)!+', r'\\1'),             # multi exclamations\n",
        "    ]\n",
        "    for pat, repl in pattern_fixes:\n",
        "        text = re.sub(pat, repl, text)\n",
        "\n",
        "    # Sentence-case pass\n",
        "    def _cap(m):\n",
        "        s = m.group(0)\n",
        "        return s[0].upper() + s[1:]\n",
        "    text = re.sub(r'(^|\\.\\s+|\\?\\s+|!\\s+)([a-z])', lambda m: m.group(1) + m.group(2).upper(), text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# 6) SRT / JSON EXPORT\n",
        "\n",
        "def srt_timestamp(t):\n",
        "    # t in seconds (float)\n",
        "    if t is None: t = 0.0\n",
        "    h = int(t // 3600)\n",
        "    m = int((t % 3600) // 60)\n",
        "    s = int(t % 60)\n",
        "    ms = int((t - int(t)) * 1000)\n",
        "    return f\"{h:02d}:{m:02d}:{s:02d},{ms:03d}\"\n",
        "\n",
        "def write_srt(segments, out_path):\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, seg in enumerate(segments, start=1):\n",
        "            start = srt_timestamp(seg[\"start\"])\n",
        "            end = srt_timestamp(seg[\"end\"])\n",
        "            txt = seg[\"text\"].strip()\n",
        "            f.write(f\"{i}\\n{start} --> {end}\\n{txt}\\n\\n\")\n",
        "\n",
        "def write_json_words(segments, out_path):\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(segments, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "\n",
        "# 7) TRANSCRIBER (faster-whisper)\n",
        "\n",
        "class TranscriberPro:\n",
        "    def __init__(self,\n",
        "                 preferred_model=\"large-v3\",\n",
        "                 language=None,                   # None = auto\n",
        "                 beam_size=5,\n",
        "                 vad=True,\n",
        "                 suppress_repetition=True):\n",
        "        self.device = DEVICE\n",
        "        self.compute_type = pick_compute_type()\n",
        "        self.language = language\n",
        "        self.beam_size = beam_size\n",
        "        self.vad = vad\n",
        "        self.suppress_repetition = suppress_repetition\n",
        "        self.model_name = self._choose_model(preferred_model)\n",
        "        rprint(f\"[bold green]Device:[/bold green] {self.device}  \"\n",
        "               f\"[bold green]Compute:[/bold green] {self.compute_type}  \"\n",
        "               f\"[bold green]Model:[/bold green] {self.model_name}\")\n",
        "        self.model = WhisperModel(self.model_name, device=self.device, compute_type=self.compute_type)\n",
        "\n",
        "    def _choose_model(self, preferred):\n",
        "      if self.device == \"cuda\":\n",
        "          return preferred\n",
        "      else:\n",
        "          return \"medium.en\"\n",
        "\n",
        "\n",
        "    # Media Ingestion\n",
        "    def from_youtube(self, url):\n",
        "        rprint(\"[bold cyan]Downloading YouTube audio...[/bold cyan]\")\n",
        "        wav = download_youtube_wav(url, out_wav=\"youtube_16k.wav\")\n",
        "        self._post_ingest_cleanup(wav)\n",
        "        return wav\n",
        "\n",
        "    def from_video(self, video_path):\n",
        "        rprint(\"[bold cyan]Extracting audio from video...[/bold cyan]\")\n",
        "        wav = \"video_16k.wav\"\n",
        "        extract_wav_16k_mono(video_path, wav)\n",
        "        self._post_ingest_cleanup(wav)\n",
        "        return wav\n",
        "\n",
        "    def from_audio(self, audio_path):\n",
        "        rprint(\"[bold cyan]Standardizing audio...[/bold cyan]\")\n",
        "        wav = \"input_16k.wav\"\n",
        "        extract_wav_16k_mono(audio_path, wav)\n",
        "        self._post_ingest_cleanup(wav)\n",
        "        return wav\n",
        "\n",
        "    def _post_ingest_cleanup(self, wav_path):\n",
        "        rprint(\"[bold cyan]Enhancing audio (normalize + noise reduce)...[/bold cyan]\")\n",
        "        normalize_lufs(wav_path)\n",
        "        reduce_noise(wav_path, out_path=wav_path, prop_decrease=0.7)\n",
        "\n",
        "    #  Transcription Core\n",
        "\n",
        "    def transcribe(self, wav_path, temperature=0.0):\n",
        "        rprint(\"[bold magenta]Transcribing with optimized parameters...[/bold magenta]\")\n",
        "\n",
        "        vad_params = dict(\n",
        "            min_speech_duration_ms=250,\n",
        "            max_speech_duration_s=30,\n",
        "            min_silence_duration_ms=450,\n",
        "            speech_pad_ms=120\n",
        "        )\n",
        "\n",
        "        segs, words = [], []\n",
        "\n",
        "        generator, info = self.model.transcribe(\n",
        "            wav_path,\n",
        "            language=self.language,\n",
        "            beam_size=self.beam_size,\n",
        "            best_of=None,\n",
        "            temperature=temperature,\n",
        "            vad_filter=self.vad,\n",
        "            vad_parameters=vad_params,\n",
        "            condition_on_previous_text=False,\n",
        "            compression_ratio_threshold=2.2,\n",
        "            no_speech_threshold=0.60,\n",
        "            log_prob_threshold=-1.2,\n",
        "            word_timestamps=True,\n",
        "            suppress_blank=True\n",
        "\n",
        "        )\n",
        "\n",
        "        for seg in generator:\n",
        "            text = (seg.text or \"\").strip()\n",
        "            if not text:\n",
        "                continue\n",
        "            start = float(seg.start or 0.0)\n",
        "            end   = float(seg.end or (start + 1.0))\n",
        "            avg_lp = float(seg.avg_logprob or -999.0)\n",
        "            no_sp  = float(seg.no_speech_prob or 0.0)\n",
        "\n",
        "\n",
        "            toks = re.findall(r'\\w+', text, flags=re.UNICODE)\n",
        "            uniq_ratio = (len(set(toks)) / max(1, len(toks))) if toks else 1.0\n",
        "            if (no_sp > 0.80 and avg_lp < -0.8) or avg_lp < -1.2 or uniq_ratio < 0.25:\n",
        "                continue\n",
        "\n",
        "            segs.append({\n",
        "                \"start\": start,\n",
        "                \"end\": end,\n",
        "                \"text\": text,\n",
        "                \"avg_logprob\": avg_lp,\n",
        "                \"no_speech_prob\": no_sp\n",
        "            })\n",
        "\n",
        "            if getattr(seg, \"words\", None):\n",
        "                for w in seg.words:\n",
        "                    words.append({\n",
        "                        \"word\": w.word,\n",
        "                        \"start\": float(w.start or start),\n",
        "                        \"end\": float(w.end or start),\n",
        "                        \"prob\": float(w.probability or 0.0)\n",
        "                    })\n",
        "\n",
        "        # Build text and clean it thoroughly\n",
        "        raw_text = \" \".join(s[\"text\"] for s in segs).strip()\n",
        "        if self.suppress_repetition:\n",
        "            raw_text = remove_repetitions(raw_text, sim_threshold=0.70)\n",
        "        final_text = context_aware_corrections(raw_text)\n",
        "\n",
        "        final_text = collapse_word_runs(final_text, max_repeat=3)\n",
        "        final_text = trim_low_info_tail(final_text, min_unique_ratio=0.25, tail_window=80)\n",
        "        final_text = smart_space_fix(final_text)\n",
        "\n",
        "\n",
        "        return final_text, segs, words\n",
        "\n",
        "\n",
        "# 8) MAIN UX (upload file / YouTube)\n",
        "\n",
        "def main():\n",
        "    rprint(\"[bold yellow] Video Transcription System[/bold yellow]\")\n",
        "    rprint(\"=\"*60)\n",
        "    rprint(\"1) Upload a VIDEO or AUDIO file\")\n",
        "    rprint(\"2) Enter a YouTube URL\")\n",
        "\n",
        "    choice = input(\"Choose option (1/2): \").strip()\n",
        "\n",
        "    # Create transcriber (Large-v3 on GPU, Medium on CPU)\n",
        "    transcriber = TranscriberPro(\n",
        "        preferred_model=\"large-v3\",\n",
        "        language=None,            # auto-detect; set \"en\" for English-only\n",
        "        beam_size=5,\n",
        "        vad=True,\n",
        "        suppress_repetition=True\n",
        "    )\n",
        "\n",
        "    src_name = \"\"\n",
        "    wav_path = None\n",
        "\n",
        "    if choice == \"1\":\n",
        "        rprint(\"[bold cyan]Please upload a video or audio file...[/bold cyan]\")\n",
        "        uploaded = files.upload()\n",
        "        if uploaded:\n",
        "            in_path = list(uploaded.keys())[0]\n",
        "            src_name = in_path\n",
        "            # Decide by extension\n",
        "            ext = Path(in_path).suffix.lower()\n",
        "            if ext in [\".wav\", \".mp3\", \".m4a\", \".flac\", \".ogg\", \".opus\"]:\n",
        "                wav_path = transcriber.from_audio(in_path)\n",
        "            else:\n",
        "                wav_path = transcriber.from_video(in_path)\n",
        "        else:\n",
        "            rprint(\"[red]No file uploaded.[/red]\")\n",
        "            return\n",
        "\n",
        "    elif choice == \"2\":\n",
        "        url = input(\"Enter YouTube URL: \").strip()\n",
        "        if not url:\n",
        "            rprint(\"[red]No URL provided.[/red]\")\n",
        "            return\n",
        "        src_name = url\n",
        "        try:\n",
        "            wav_path = transcriber.from_youtube(url)\n",
        "        except Exception as e:\n",
        "            rprint(f\"[red]YouTube download failed: {e}[/red]\")\n",
        "            return\n",
        "\n",
        "\n",
        "    else:\n",
        "        rprint(\"[red]Invalid choice.[/red]\")\n",
        "        return\n",
        "\n",
        "    # Transcribe\n",
        "    try:\n",
        "        final_text, segs, words = transcriber.transcribe(wav_path, temperature=0.0)\n",
        "    except RuntimeError as e:\n",
        "        # If GPU OOM with large-v3, fallback to medium.en automatically\n",
        "        if \"out of memory\" in str(e).lower() or \"cuda\" in str(e).lower():\n",
        "            rprint(\"[yellow]GPU ran out of memory. Falling back to 'medium.en'...[/yellow]\")\n",
        "            transcriber = TranscriberPro(\n",
        "                preferred_model=\"medium.en\",\n",
        "                language=None,\n",
        "                beam_size=5,\n",
        "                vad=True,\n",
        "                suppress_repetition=True\n",
        "            )\n",
        "            final_text, segs, words = transcriber.transcribe(wav_path, temperature=0.0)\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "    # Save outputs\n",
        "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    base = f\"transcription_{ts}\"\n",
        "    txt_path = f\"{base}.txt\"\n",
        "    srt_path = f\"{base}.srt\"\n",
        "    json_path = f\"{base}_words.json\"\n",
        "\n",
        "    with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"ENHANCED VIDEO TRANSCRIPTION\\n\")\n",
        "        f.write(\"=\"*50 + \"\\n\\n\")\n",
        "        f.write(f\"Source: {src_name}\\n\")\n",
        "        f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(\"=\"*50 + \"\\n\\n\")\n",
        "        f.write(final_text.strip() + \"\\n\")\n",
        "\n",
        "    # Build SRT segments with cleaned sentence chunks (merge short lines)\n",
        "    srt_ready = []\n",
        "    for s in segs:\n",
        "        if s[\"text\"].strip():\n",
        "            srt_ready.append({\n",
        "                \"start\": s[\"start\"],\n",
        "                \"end\": s[\"end\"],\n",
        "                \"text\": s[\"text\"].strip()\n",
        "            })\n",
        "    write_srt(srt_ready, srt_path)\n",
        "    write_json_words(words, json_path)\n",
        "\n",
        "    rprint(\"\\n\" + \"=\"*60)\n",
        "    rprint(\"[bold green]ENHANCED TRANSCRIPTION RESULT:[/bold green]\")\n",
        "    rprint(\"=\"*60)\n",
        "    print(final_text)\n",
        "\n",
        "    rprint(f\"\\n[bold]Saved:[/bold] {txt_path}, {srt_path}, {json_path}\")\n",
        "    # Offer downloads\n",
        "    files.download(txt_path)\n",
        "    files.download(srt_path)\n",
        "    files.download(json_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "Urj7RwKOF1G9",
        "outputId": "fbe7a770-9a31-4b39-c88c-1032fcba05a2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;33m Video Transcription System\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> Video Transcription System</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "============================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">============================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m Upload a VIDEO or AUDIO file\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span> Upload a VIDEO or AUDIO file\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m Enter a YouTube URL\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span> Enter a YouTube URL\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose option (1/2): 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mDevice:\u001b[0m cuda  \u001b[1;32mCompute:\u001b[0m int8_float16  \u001b[1;32mModel:\u001b[0m large-v3\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Device:</span> cuda  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Compute:</span> int8_float16  <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Model:</span> large-v3\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36mPlease upload a video or audio file\u001b[0m\u001b[1;36m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Please upload a video or audio file...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-858d79b1-cf0b-4faf-af43-de2fe67bbf0b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-858d79b1-cf0b-4faf-af43-de2fe67bbf0b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving WIN_20250831_04_55_17_Pro.mp4 to WIN_20250831_04_55_17_Pro.mp4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36mExtracting audio from video\u001b[0m\u001b[1;36m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Extracting audio from video...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;36mEnhancing audio \u001b[0m\u001b[1;36m(\u001b[0m\u001b[1;36mnormalize + noise reduce\u001b[0m\u001b[1;36m)\u001b[0m\u001b[1;36m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Enhancing audio (normalize + noise reduce)...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;35mTranscribing with optimized parameters\u001b[0m\u001b[1;35m...\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Transcribing with optimized parameters...</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "============================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "============================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1;32mENHANCED TRANSCRIPTION RESULT:\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">ENHANCED TRANSCRIPTION RESULT:</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "============================================================\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">============================================================\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, my name is Anishka Raz.I am third year undergrad of IIT Kanpur.I am from Ayodhya, Uttar Pradesh, India.I am doing my B.Tech from Mechanical Engineering in IIT Kanpur.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n",
              "\u001b[1mSaved:\u001b[0m transcription_20250830_233121.txt, transcription_20250830_233121.srt, \n",
              "transcription_20250830_233121_words.json\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "<span style=\"font-weight: bold\">Saved:</span> transcription_20250830_233121.txt, transcription_20250830_233121.srt, \n",
              "transcription_20250830_233121_words.json\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b03398a9-c433-4b85-ab51-242f1228b829\", \"transcription_20250830_233121.txt\", 379)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ae0c6a71-2abd-4a3c-b305-96c06f3bb6d9\", \"transcription_20250830_233121.srt\", 276)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_54247d07-6149-4f8e-8a7c-0cecb7b6cf41\", \"transcription_20250830_233121_words.json\", 3078)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}